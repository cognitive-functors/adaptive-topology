# C4 для исследователей ИИ

Как Полная когнитивная координатная система позволяет проводить структурированную многометочную классификацию когнитивных состояний: готовая к продакшну архитектура на базе DeBERTa и результаты бенчмарков.

---

## Постановка задачи

Дан текстовый сегмент (предложение, параграф или дискурсивная единица). Требуется предсказать его когнитивные координаты:

```
f(text) -> (T, D, A) in {0, 1, 2}^3
```

Где:
- **T (Время):** Прошлое (0) / Настоящее (1) / Будущее (2)
- **D (Масштаб):** Конкретное (0) / Абстрактное (1) / Мета (2)
- **A (Агентность, agency):** Я (0) / Другой (1) / Система (2)

Это задача **структурированной многометочной классификации (structured multi-label classification)**: три коррелированных ординальных выхода, каждый с 3 классами. Пространство меток содержит 27 возможных комбинаций.

---

## Почему это важно для ИИ

1. **Интерпретируемое снижение размерности:** Текстовые эмбеддинги живут в R^768+. C4 отображает их в Z3^3 (27 дискретных состояний), сохраняя когнитивно осмысленную структуру. Это аналогично PCA, но с семантически обоснованными осями.

2. **Тестируемая гипотеза:** Если утверждение C4 верно, *внутренняя размерность (intrinsic dimension)* когнитивных текстовых эмбеддингов должна быть приблизительно равна 3. Это независимо проверяемое предсказание (см. раздел о фальсификации).

3. **Архитектура ИИ-агентов:** Координаты C4 могут служить структурированным представлением состояния для когнитивных агентов, обеспечивая явное рассуждение о временном горизонте, уровне абстракции и перспективе.

4. **Выравнивание (alignment):** C4 предоставляет формальный словарь для описания того, "о чём думает" система ИИ -- какой временной горизонт, какой уровень абстракции, чья перспектива.

---

## Архитектура: опубликованная модель на HuggingFace

### Обзор

Опубликованная модель использует DeBERTa-v3-base в качестве основы с архитектурой многоголовой классификации:

```
Входной текст
 |
[Энкодер DeBERTa-v3-base]
 |
[CLS-представление токена] (768-мерное)
 |
 +---> [T-голова] -> softmax(3) -- Предсказание Времени
 +---> [D-голова] -> softmax(3) -- Предсказание Масштаба
 +---> [A-голова] -> softmax(3) -- Предсказание Агентности
```

### Особенности модели

- **65 классификационных голов** в 12 LoRA-адаптерах
- **12 модулей LoRA-адаптеров:** специализированных для различных текстовых доменов и задач классификации
- **Ансамбль:** Финальное предсказание -- мажоритарное голосование по головам, уверенность = доля согласия
- **Обучение:** Многозадачная функция потерь = L_T + L_D + L_A с весами классов для компенсации дисбаланса меток

### Почему 65 голов?

Одноголовые классификаторы достигают ~75% точности по осям. Ансамбль из 65 голов со специализацией адаптеров достигает ~85-88% точности по осям за счёт:
- Снижения дисперсии через усреднение
- Захвата доменно-специфичных паттернов через адаптеры
- Предоставления калиброванных оценок уверенности (высокое согласие = высокая уверенность)

---

## Обучающие данные

### Источники данных

| Источник | Объём | Описание |
|----------|-------|----------|
| Экспертная разметка | ~5K примеров | Золотой стандарт, тройная разметка с арбитражем |
| С помощью LLM | ~50K примеров | Разметка GPT-4 / Claude, фильтрация по консистентности |
| Полуконтролируемая | ~200K примеров | Высокоуверенные предсказания V5/V6, верифицированное людьми подмножество |

### Протокол разметки

1. Аннотатор читает текстовый сегмент
2. Присваивает T из {Прошлое, Настоящее, Будущее}
3. Присваивает D из {Конкретное, Абстрактное, Мета}
4. Присваивает A из {Я, Другой, Система}
5. Флаг уверенности: {определённо, неопределённо}
6. Межаннотаторское согласие: требуется каппа Коэна > 0.7

### Распределение меток

Пространство меток неравномерно. Частые состояния:
- (1, 1, 2) = Настоящее/Абстрактное/Система -- академический/аналитический текст (наиболее частое)
- (0, 0, 0) = Прошлое/Конкретное/Я -- личный нарратив
- (1, 0, 0) = Настоящее/Конкретное/Я -- экспериенциальный отчёт

Редкие состояния:
- (2, 2, 1) = Будущее/Мета/Другой -- антиципация метакогниции другого
- (0, 2, 2) = Прошлое/Мета/Система -- исторический мета-анализ системных процессов

Для компенсации дисбаланса применяется взвешивание классов.

---

## Бенчмарки

### Точность по осям (тестовый набор)

| Ось | Точность (accuracy) | Макро-F1 | Примечания |
|-----|---------------------|----------|-----------|
| T (Время) | 87.2% | 0.85 | Будущее -- наиболее сложное (меньше примеров) |
| D (Масштаб) | 83.5% | 0.81 | Граница Мета vs. Абстрактное размыта |
| A (Агентность) | 85.8% | 0.84 | Система vs. Другой требует контекста |

### Совместная точность

- **Точное совпадение (все 3 верны):** 68.4%
- **Точность по Хэммингу (среднее по осям):** 85.5%
- **В пределах расстояния Хэмминга 1:** 91.2%

### Сравнение

| Модель | Точное совпадение | Точность по Хэммингу |
|--------|-------------------|----------------------|
| Мажоритарная бейзлайн | 12.3% | 48.1% |
| BERT-base (одна голова) | 54.7% | 78.3% |
| DeBERTa V5 (12 голов) | 61.2% | 82.1% |
| DeBERTa (65 голов, 12 LoRA-адаптеров) | 68.4% | 85.5% |

---

## Протокол фальсификации

C4 делает тестируемое предсказание: внутренняя размерность когнитивных текстовых эмбеддингов приблизительно равна 3.

**Метод:**
1. Закодировать большой корпус (>100K предложений) с помощью предобученной языковой модели
2. Применить оценку внутренней размерности (например, MLE, TwoNN)
3. Если внутренняя размерность >> 3, утверждение C4 о достаточности 3 осей ставится под сомнение
4. Если внутренняя размерность приблизительно равна 3, это независимое свидетельство в пользу C4

**Текущий статус:** Предварительные результаты на 10K примерах указывают на внутреннюю размерность в диапазоне 2.8-4.2, что согласуется с гипотезой, но пока не является окончательным. Планируются более масштабные исследования.

---

## Интеграция с системами ИИ

### В качестве представления состояния

```python
# Псевдокод для C4-осведомлённого агента
state = c4_classifier(observation_text) # -> (T, D, A)

if state.T == FUTURE and state.D == META:
 # Агент в режиме стратегического планирования
 route_to_planner()
elif state.T == PRESENT and state.D == CONCRETE:
 # Агент в режиме исполнения
 route_to_executor()
```

### Дашборд покрытия

Для ИИ-агентов, обрабатывающих многоходовые разговоры, отслеживание посещённых состояний C4:

```
Покрытие: 14/27 состояний посещено (51.9%)
Пропущено: квадрант Будущее-Мета, столбец Прошлое-Система
Рекомендация: побудить агента рассмотреть долгосрочную системную перспективу
```

Это обеспечивает метакогнитивный мониторинг: агент способен обнаруживать собственные когнитивные слепые пятна.

---

## Воспроизведение результатов

Код, обученные модели и скрипты оценки доступны по адресу:
`https://github.com/cognitive-functors/adaptive-topology`

### Быстрый старт

```bash
pip install torch transformers datasets
python evaluate.py --model c4-cognitive-adapters --data test_set.jsonl
```

---

## Открытые проблемы

1. **Кросс-лингвальный перенос (cross-lingual transfer):** Обобщается ли модель, обученная на английском, на другие языки? (Гипотеза: да, поскольку C4 языково-независима.)
2. **Мелкозернистая рекурсия:** Может ли каждое из 27 состояний быть подразделено на 27 подсостояний, как предсказывает фрактальная гипотеза?
3. **Темпоральная динамика:** Моделирование переходов состояний C4 по дискурсивному времени (разметка последовательностей вместо классификации отдельных предложений).
4. **Нейронные корреляты:** Отображение состояний C4 на паттерны активации фМРТ.

---

## Литература

- He, P. et al. (2021). "DeBERTa: Decoding-enhanced BERT with Disentangled Attention." ICLR 2021.
- Selyutin, I. & Kovalev, N. (2025). "C4: Complete Cognitive Coordinate System." Preprint.

---

*Контакт: psy.seliger@yandex.ru / comonoid@yandex.ru*
