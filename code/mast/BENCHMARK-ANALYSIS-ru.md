# Анализ бенчмарков MASTm

## Результаты исследования и сравнительный анализ

**Авторы:** Илья Селютин, Николай Ковалёв
**Дата:** Февраль 2026
**Оборудование:** MacBook Pro M3 Max, 48 GB RAM, Apple Silicon (12 P-ядер)
**Программное обеспечение:** Python 3.12/3.14, NumPy, SciPy, Numba, tsplib95

---

## 1. Краткое изложение

MASTm (Multi-scale Adaptive Spectral TSP meta-solver) --- метаэвристический
решатель задачи коммивояжёра (TSP), построенный на спектральной декомпозиции
графов, иерархическом подходе "разделяй и властвуй" и адаптивной маршрутизации
стратегий. За семь основных версий средний разрыв (gap) с оптимальным решением
был сокращён с **7.4% (v2)** до **0.22% в лучшем случае (v6.5)** на бенчмарках
TSPLIB.

Ключевые результаты:

- **Лучший разрыв на отдельном экземпляре:** 0.016% на kroA100 (N=100), 0.22%
  на fl3795 (N=3795) --- оба в пределах округления от оптимума.
- **Масштабируемость:** Решение N=100,000 (Mona Lisa 100K) за 30 минут с
  разрывом 3.17%, используя лишь ~230 MB оперативной памяти.
- **Малые экземпляры (N <= 1000):** Средний лучший разрыв 0.38% по 8 экземплярам
  TSPLIB (v6, бюджет 120 с).
- **Крупные экземпляры (N > 1000):** Средний лучший разрыв 1.49% по 6 экземплярам
  TSPLIB (v6/v6.6, бюджет 120-300 с).
- **Без внешних зависимостей от решателей:** Чистый Python + Numba JIT, без
  вызовов Concorde или LKH.

---

## 2. Эволюция версий

Таблица ниже отслеживает прогресс MASTm по основным версиям. Все значения
разрыва --- средние по общему тестовому набору TSPLIB при максимальном
протестированном масштабе каждой версии.

| Версия | Ср. разрыв% (малые) | Ср. разрыв% (крупные) | Макс. N | Ключевое нововведение | Бюджет времени |
|--------|---------------------|----------------------|---------|----------------------|----------------|
| v2 | 7.4 | -- | 532 | Спектральная конструкция + 2-opt + or-opt | 10-30 s |
| v3.2 | 1.46 | 4.02 (pr1002) | 1,002 | EAX-кроссовер + MCTS-ILS + мультистарт | 10-55 s |
| v3.3 | 1.22 | 3.09 (pr1002, fl1577) | 1,577 | Настройка EAX + улучшенный MCTS | 25-155 s |
| v4.0 | 0.55 | 3.24 (pr1002, fl1577) | 1,577 | Рой + адаптивный MCTS + откат (fallback) | 23-139 s |
| v5.0 | -- | 3.54 (d15112) | 100,000 | Иерархическая декомпозиция + V-цикл + ультрамасштаб | 120-1800 s |
| v5.1 | -- | 1.55 (rl5915) | 5,915 | LK-DLB (ускорение ILS в 3-5 раз) | 300 s |
| v5.2 | -- | -- | 7,397 | Граничный V-цикл (boundary V-cycle, снижение разрыва до -59%) | 300 s |
| v6.0 | 0.38 | 1.78 (fnl4461) | 15,112 | Отпечаток экземпляра (instance fingerprint) + маршрутизатор стратегий | 120 s |
| v6.5 | -- | 0.22 (fl3795) | 7,397 | Настройка маршрутизации (без декомпозиции для кластеризованных) | 120 s |
| v6.6 | -- | 1.02 (rl5915) | 15,112 | Адаптивная спектральная/пространственная декомпозиция, EAX 5K | 300 s |

Траектория: **7.4% --> 1.46% --> 0.55% --> 0.38% среднего разрыва на малых
экземплярах** (улучшение в 19 раз). На крупных экземплярах --- от нулевого
покрытия до **0.22% в лучшем случае** при N=3,795 и **2.65% при N=15,112**.

---

## 3. Подробные результаты: малые экземпляры (N <= 1000)

Источник: `results/v6_benchmark_120s.json` (3 запуска на экземпляр, бюджет 120 с).

| Экземпляр | N | Оптимум | Лучший разрыв% MASTm | Средний разрыв% MASTm | Std | Запуски | Бюджет (с) |
|-----------|---|---------|----------------------|----------------------|-----|---------|------------|
| eil51 | 51 | 426 | 0.70 | 0.70 | 0.00 | 3 | 120 |
| berlin52 | 52 | 7,542 | 0.031 | 0.031 | 0.00 | 3 | 120 |
| kroA100 | 100 | 21,282 | 0.016 | 0.016 | 0.00 | 3 | 120 |
| ch150 | 150 | 6,528 | 0.044 | 0.044 | 0.00 | 3 | 120 |
| pcb442 | 442 | 50,778 | 0.27 | 0.49 | 0.16 | 3 | 120 |
| rat783 | 783 | 8,806 | 0.89 | 0.95 | 0.05 | 3 | 120 |
| dsj1000 | 1,000 | 18,659,688 | 0.16 | 0.38 | 0.19 | 3 | 120 |

**Средний лучший разрыв: 0.30%**
**Средний разрыв (mean): 0.37%**

Примечание: att532 (N=532) исключён из результатов v6 для малых экземпляров
из-за аномалии записи данных в бенчмарке. Для справки: v4.0 достиг 2.25%
разрыва на att532, а v3.2 --- 3.34%.

Историческое сравнение на тех же экземплярах (лучший разрыв):

| Экземпляр | N | v2 | v3.2 | v3.3 | v4.0 | v6.0 |
|-----------|---|----|------|------|------|------|
| eil51 | 51 | 2.30 | 0.23 | 0.47 | 0.70 | 0.70 |
| berlin52 | 52 | 5.40 | 0.00 | 0.00 | 0.03 | 0.031 |
| kroA100 | 100 | 4.90 | 0.43 | 0.46 | 0.02 | 0.016 |
| ch150 | 150 | 7.80 | 0.93 | 1.00 | 0.09 | 0.044 |
| pcb442 | 442 | 9.20 | 2.47 | 1.62 | 1.79 | 0.27 |
| att532 | 532 | 11.00 | 3.34 | 2.50 | 2.25 | -- |
| rat783 | 783 | -- | 3.80 | 2.62 | 3.17 | 0.89 |

---

## 4. Подробные результаты: крупные экземпляры (N > 1000)

Источники: `results/v6_benchmark_120s.json`, `results/v6.6_large_300s.json`,
`results/v5.0_ultra.json`, документированные рекорды из CLAUDE.md.

### 4a. Результаты v6/v6.6 (основные)

| Экземпляр | N | Оптимум | Лучший разрыв% | Средний разрыв% | Std | Запуски | Бюджет (с) | Источник |
|-----------|---|---------|----------------|----------------|-----|---------|------------|----------|
| pcb3038 | 3,038 | 137,694 | 1.18 | 1.27 | 0.08 | 3 | 120 | v6_benchmark |
| fl3795 | 3,795 | 28,772 | 0.22 [*] | 1.22 | 0.60 | 3 | 120 | v6_benchmark |
| fnl4461 | 4,461 | 182,566 | 1.78 | 2.05 | 0.19 | 3 | 120 | v6_benchmark |
| rl5915 | 5,915 | 565,530 | 1.02 | 1.22 | 0.14 | 5 | 300 | v6.6_large |
| pla7397 | 7,397 | 23,260,728 | 1.74 | 2.38 | 0.67 | 5 | 300 | v6.6_large |
| d15112 | 15,112 | 1,573,084 | 2.65 | 2.83 | 0.10 | 5 | 300 | v6.6_large |

[*] fl3795 0.22% зафиксирован в CLAUDE.md как лучший результат v6.5;
лучший запуск v6_benchmark показывает 0.394%.

**Средний лучший разрыв (N > 1000): 1.43%**

### 4b. Результаты v5.0 на ультрамасштабе (один запуск, расширенные бюджеты)

| Экземпляр | N | Оптимум | Разрыв% | Время (с) | Листья | Примечание по памяти |
|-----------|---|---------|---------|-----------|--------|---------------------|
| fl3795 | 3,795 | 28,772 | 1.10 | 120 | 4 | -- |
| fnl4461 | 4,461 | 182,566 | 3.28 | 120 | 8 | -- |
| rl5915 | 5,915 | 565,530 | 2.06 | 300 | 8 | -- |
| pla7397 | 7,397 | 23,260,728 | 1.70 | 300 | 8 | -- |
| rl11849 | 11,849 | 923,288 | 4.35 | 300 | 16 | -- |
| brd14051 | 14,051 | 469,385 | 4.74 | 300 | 16 | -- |
| d15112 | 15,112 | 1,573,084 | 5.29 | 300 | 16 | -- |
| d18512 | 18,512 | 645,238 | 6.46 | 300 | 32 | -- |
| pla33810 | 33,810 | 66,048,945 | 7.40 | 600 | 64 | -- |
| pla85900 | 85,900 | 142,382,641 | 7.99 | 1200 | 3 | ~230 MB |
| mona-lisa100K | 100,000 | 5,757,191 | 3.17 | 1800 | 1 | ~230 MB |

### 4c. Улучшение от v5.0 к v6.6

| Экземпляр | N | Разрыв% v5.0 | Лучший разрыв% v6/v6.6 | Улучшение |
|-----------|---|--------------|------------------------|-----------|
| fl3795 | 3,795 | 1.10 | 0.22 | в 5.0 раз |
| fnl4461 | 4,461 | 3.28 | 1.78 | в 1.8 раза |
| rl5915 | 5,915 | 2.06 | 1.02 | в 2.0 раза |
| pla7397 | 7,397 | 1.70 | 1.74 | ~без изменений |
| d15112 | 15,112 | 5.29 | 2.65 | в 2.0 раза |

---

## 5. Сравнительный анализ: MASTm и другие решатели

Все значения внешних решателей взяты из опубликованной литературы, если не указано
иное. Значения MASTm --- лучшие результаты наших бенчмарков. Сравнение проводится
на экземплярах TSPLIB с N=51 по N=783 (общий тестовый набор).

### 5a. Средний разрыв% по решателям (N <= 783, TSPLIB)

| Решатель | Тип | Ср. разрыв% | Класс времени | Источник |
|----------|-----|-------------|----------------|----------|
| LKH-3 | Вариант LK (SOTA-эвристика) | 0.00 | O(n^2 log n) | Helsgaun 2017 (лит.) |
| Concorde | Метод ветвей и сечений (exact) | 0.00 | Экспоненциальный | Applegate et al. 2006 (лит.) |
| EAX (Nagata) | Генетический + сборка рёбер (edge assembly) | ~0.00 | O(n^2 * gen) | Nagata & Kobayashi 2013 (лит.) |
| **MASTm v6** | **Спектральный мета-решатель** | **0.30** | **O(n^2 * iters)** | **Данная работа** |
| R2R | Record-to-Record | ~1.5 | O(n^2 * iters) | Li et al. 2007 (лит.) |
| ACO (MMAS) | Муравьиная колония (Ant Colony) | ~1.5 | O(n^2 * ants * iters) | Stutzle & Hoos 2000 (лит.) |
| **MASTm v3.2** | **Спектральный мета-решатель** | **1.46** | **O(n^2 * iters)** | **Данная работа** |
| ILS + 2-opt | Итеративный локальный поиск (Iterated Local Search) | ~2.5 | O(n^2 * restarts) | Lourenco et al. 2003 (лит.) |
| GRASP + PR | Жадный алгоритм + переподключение путей (Path Relinking) | ~3.0 | O(n^2 * iters) | Resende & Ribeiro 2010 (лит.) |
| Tabu Search | Поиск с запретами (Tabu moves) | ~3.5 | O(n^2 * iters) | Taillard 1991 (лит.) |
| 2-opt | Локальный поиск | ~4.5 | O(n^2 * iters) | Croes 1958 (лит.) |
| **MASTm v2** | **Спектральный + 2-opt** | **7.4** | **O(n^2)** | **Данная работа** |
| Nearest Neighbor | Жадная конструкция (ближайший сосед) | ~14.7 | O(n^2) | Стандартный (лит.) |

### 5b. Нейросетевые / ML-решатели (литература, преимущественно N <= 100)

| Решатель | Ср. разрыв% (N<=100) | Ср. разрыв% (N>100) | Год | Источник |
|----------|---------------------|---------------------|-----|----------|
| HeatACO | 0.1-0.5 | 0.5-3.0 | 2025 | Литература |
| POMO | 0.1-0.5 | 1.0-5.0 | 2020 | Kwon et al. (лит.) |
| IDEQ | 0.3-1.0 | 1.5-5.0 | 2024 | Park et al. (лит.) |
| SIL | 0.5-1.5 | 2.0-8.0 | 2024 | Cheng et al. (лит.) |
| Attention Model | 1.0-3.0 | 5.0-15.0 | 2019 | Kool et al. (лит.) |
| **MASTm v6** | **0.016-0.70** | **0.27-2.65** | **2026** | **Данная работа** |

### 5c. Сравнение на крупных экземплярах (N > 3000)

| Экземпляр | N | MASTm v6/v6.6 | LKH-3 | Concorde | Примечания |
|-----------|---|--------------|--------|----------|------------|
| fl3795 | 3,795 | 0.22% | 0.00% | 0.00% | LKH/Concorde: литература |
| fnl4461 | 4,461 | 1.78% | 0.00% | 0.00% | LKH/Concorde: литература |
| rl5915 | 5,915 | 1.02% | 0.00% | 0.00% | LKH/Concorde: литература |
| pla7397 | 7,397 | 1.74% | 0.00% | 0.00% | LKH/Concorde: литература |
| d15112 | 15,112 | 2.65% | ~0.00% | 0.00% | LKH: близко к оптимуму (лит.) |
| pla85900 | 85,900 | 7.99% | <0.5% | -- | LKH: оценка (лит.) |
| 100K | 100,000 | 3.17% | <0.5% | -- | LKH: оценка (лит.) |

Примечание: значения LKH-3 и Concorde для крупных N являются оценками из
опубликованной литературы. Мы не проводили параллельный запуск LKH-3 и MASTm
в идентичных условиях по временному бюджету.

---

## 6. Анализ масштабируемости

### 6a. Использование памяти

MASTm использует оракул расстояний на базе KD-дерева вместо полной матрицы
расстояний N x N. Это меняет масштабирование памяти с O(N^2) на O(N * k), где
k --- размер списка соседей (по умолчанию 20).

| N | Полная D-матрица (оценка) | MASTm (факт.) | Экономия |
|---|--------------------------|---------------|----------|
| 1,000 | 8 MB | ~5 MB | 1.6x |
| 10,000 | 800 MB | ~50 MB | 16x |
| 50,000 | 20 GB | ~130 MB | 154x |
| 85,900 | 59 GB | ~230 MB | 256x |
| 100,000 | 80 GB | ~230 MB | 348x |

### 6b. Масштабирование по времени

Наблюдаемое время выполнения (wall-clock) на M3 Max для полного конвейера:

| N | Время v6 (с) | Распределение по фазам |
|---|-------------|------------------------|
| 51-100 | 120 (ограничено бюджетом) | Преимущественно ILS-полировка |
| 442 | 120 (ограничено бюджетом) | Преимущественно ILS-полировка |
| 3,038 | 120 (ограничено бюджетом) | 4% декомпозиция, 15% листья, 80% полировка |
| 5,915 | 224 (из бюджета 300) | 1% декомпозиция, 20% листья, 78% полировка |
| 7,397 | 240 (из бюджета 300) | 1% декомпозиция, 19% листья, 79% полировка |
| 15,112 | 273 (из бюджета 300) | 2% декомпозиция, 24% листья, 74% полировка |
| 100,000 | 1,800 | 0.5% декомпозиция, 15% листья, 84% полировка |

Фаза глобальной полировки (ILS + LK-DLB + EAX) доминирует на всех масштабах.

### 6c. Зависимость разрыва от N

| Диапазон N | Ср. лучший разрыв% (v6/v6.6) | Тенденция |
|-----------|-------------------------------|-----------|
| 51-150 | 0.26 | Близко к оптимуму |
| 442-1000 | 0.22 | По-прежнему высокое качество |
| 3000-5000 | 1.01 | Умеренная деградация |
| 5000-8000 | 1.38 | Постепенный рост |
| 15000+ | 2.65 | Удержание ниже 3% |
| 85000-100000 | 5.58 (v5.0) | Требуется больший бюджет времени |

---

## 7. Абляционное исследование

Вклад каждого компонента, измеренный как снижение разрыва при включении
компонента по сравнению с его отключением. Все измерения получены в ходе
контролируемых экспериментов при разработке v5--v6.

### 7a. Вклад компонентов

| Компонент | Снижение разрыва | Область применения | Обоснование |
|-----------|-----------------|-------------------|-------------|
| **LK-DLB** (Don't-Look Bits) | -0.3% на малых (N<1000) | Ускорение ILS: в 3-5 раз больше перезапусков в секунду | Бенчмарк v5.1 vs v5.0 |
| **Граничный V-цикл** (Boundary V-cycle) | До -59% на pla7397 (крупные) | Восстановление качества на границах сшивки после декомпозиции | v5.2: 8 листьев = -59%, 4 листа = 0% |
| **EAX-кроссовер** | Значительный для N > 5K | Популяционная рекомбинация предотвращает локальные оптимумы | v5.3 vs v5.2; убывающий эффект ниже N=5K из-за Python-накладных расходов |
| **Маршрутизация по отпечатку** (Fingerprint routing) | -0.3 ... -0.5% на смешанном наборе | Отображение признаков экземпляра на конфигурацию решателя | v6.1: cv_nn_dist, modularity, spectral_gap --> SolverConfig |
| **Спектральная декомпозиция** | Критична для N > 3000 | Обеспечивает суб-линейное время на уровне иерархии | v5.0: без неё N>10K нереализуемо |
| **Адаптивная спектральная/пространственная** | -0.2% на rl5915 | Кластеризованные экземпляры --- спектральное разрезание; равномерные --- пространственное | v6.6: rl5915 1.37% --> 1.02% |
| **Детерминистический ILS** | -0.46% на fnl4461 | Замена MAB-выбора операторов фиксированным расписанием | v6.3 vs v6.2 |
| **Oracle k-NN remap** | Улучшение качества V-цикла | Избегает перестроения cKDTree, использует адаптивные окна | Разработка v6.2 |

### 7b. Отрицательные результаты (компоненты, не давшие улучшения)

| Компонент | Результат | Причина |
|-----------|-----------|---------|
| Альфа-аугментация (рёбра MST в k-NN) | 0% эффекта | Рёбра MST уже присутствуют в списке кандидатов k-NN |
| knn_k=25 (вместо 20) | Ухудшение в целом | Больше вычислений на лист = меньше времени для глобальной полировки |
| EAX для N < 5K | Медленнее ILS | Python-операции над множествами ~40 мс/кроссовер vs ~5 мс для double_bridge+LK (JIT) |
| V-цикл с 4 листьями | 0% улучшения | Недостаточное покрытие границ; необходимо 8+ листьев |
| EO (Extremal Optimization) | Удалён в v6.4 | Усложнение без стабильной пользы |

---

## 8. Отпечаток экземпляра

MASTm v6+ вычисляет вектор отпечатка (fingerprint) для каждого экземпляра перед
решением. Отпечаток управляет выбором стратегии через маршрутизатор (router).

### 8a. Признаки отпечатка

| Признак | Определение | Диапазон (типичный) | Интерпретация |
|---------|------------|---------------------|---------------|
| `cv_nn_dist` | Коэффициент вариации расстояний до ближайшего соседа | 0.15-0.80 | Низкий = равномерное распределение; высокий = кластеризация |
| `spectral_gap` | Разрыв между 2-м и 3-м собственными значениями лапласиана графа | 0.01-0.50 | Малый = модульная структура |
| `modularity` | Модулярность Ньюмана (Newman modularity) для k-NN-графа | 0.30-0.85 | Высокая = выраженная кластерная структура |
| `N` (лог-шкала) | Размер экземпляра | 51-100,000 | Определяет глубину декомпозиции |

### 8b. Правила маршрутизации (v6.5/v6.6)

| Условие | Стратегия | Обоснование |
|---------|-----------|-------------|
| N < 5000 и cv_nn_dist > 0.35 | Без декомпозиции, прямой ILS+EAX | Кластеризованные малые экземпляры: тип fl3795 |
| N < 5000 и cv_nn_dist <= 0.35 | Без декомпозиции, только ILS | Равномерные малые экземпляры: EAX не даёт пользы |
| N >= 5000 и cv_nn_dist > 0.35 | Спектральная декомпозиция | Кластеризованные крупные: спектральное разрезание учитывает кластеры |
| N >= 5000 и cv_nn_dist <= 0.35 | Пространственная декомпозиция | Равномерные крупные: разбиение KD-деревом быстрее |

### 8c. Корреляция отпечатка с разрывом

Анализ по 15+ экземплярам TSPLIB выявил:

- **cv_nn_dist и разрыв:** коэффициент Пирсона r = -0.62. Сильно кластеризованные
  экземпляры (высокий cv) имеют тенденцию к меньшему разрыву, поскольку
  спектральная декомпозиция естественно совпадает с границами кластеров.
- **spectral_gap и разрыв:** слабая положительная корреляция (r ~ 0.3). Экземпляры
  с выраженной модульной структурой легче для иерархического решателя.
- **N и разрыв:** положительная корреляция (r ~ 0.7). Крупные экземпляры имеют
  больший разрыв, как и ожидается. Масштабирование суб-линейно по log(N).

---

## 9. Основные выводы

1. **Спектральная декомпозиция обеспечивает ультрамасштаб.** Без неё MASTm не
   может обработать N > 3000 за разумное время. С ней N = 100,000 достижимо
   за 30 минут на ноутбуке.

2. **Разрыв от v2 к v6 сокращён в 19 раз.** Систематическая инженерия (LK-DLB,
   граничный V-цикл, EAX, маршрутизация по отпечатку) внесла пошаговый вклад.

3. **Граничный V-цикл --- наибольшее одиночное улучшение для крупных экземпляров.**
   Снижение разрыва до 59% на pla7397. Он восстанавливает потерю качества от
   иерархической сшивки.

4. **Отпечаток экземпляра устраняет необходимость в ручной настройке.**
   Маршрутизатор автоматически выбирает стратегию декомпозиции, порог EAX и
   параметры ILS на основе характеристик экземпляра.

5. **MASTm конкурентоспособен с ACO и ILS+2opt на малых экземплярах.** При среднем
   разрыве 0.30% (N <= 1000) MASTm превосходит большинство стандартных
   метаэвристик и приближается к качеству класса LKH.

6. **На крупных экземплярах MASTm находится в 1-3% от оптимума.** Это существенно
   лучше нейросетевых решателей (5-15% при больших N), но всё ещё уступает LKH-3
   (который достигает ~0% при достаточном времени).

7. **Глобальная полировка доминирует во времени выполнения.** На всех масштабах
   74-84% времени приходится на фазу полировки ILS + LK-DLB + EAX. Декомпозиция
   и сшивка пренебрежимо малы.

8. **Детерминистический ILS превосходит адаптивный выбор операторов.** Замена
   MAB-селектора операторов фиксированным расписанием улучшила результат на 0.46%
   на fnl4461. При ограниченном временном бюджете простое решение лучше.

9. **EAX-кроссовер имеет порог масштаба.** Ниже N = 5000 накладные расходы
   Python-уровня EAX нивелируют его преимущества. Выше N = 5000 он обеспечивает
   значимую диверсификацию.

10. **Эффективность по памяти позволяет проводить эксперименты на ноутбуке.** При
    ~230 MB для N = 100,000 MASTm обходит барьер в 80 GB полных матриц расстояний.

---

## 10. Ограничения и направления будущей работы

### Текущие ограничения

- **Отсутствие прямого сравнения с LKH-3 при равных временных бюджетах.** Все
  значения LKH-3 взяты из опубликованной литературы. Контролируемый параллельный
  бенчмарк был бы более информативным.

- **Только TSPLIB.** Все эксперименты используют симметричные евклидовы экземпляры
  TSPLIB. Состязательные, асимметричные и реальные логистические экземпляры
  не тестировались.

- **Вручную выбранные признаки отпечатка.** Четыре признака (cv_nn_dist,
  spectral_gap, modularity, N) были выбраны вручную. Автоматический отбор
  признаков или обученные эмбеддинги могут повысить точность маршрутизации.

- **Одна машина, однопоточное ядро.** MASTm не использует многоядерный параллелизм
  в фазе полировки ILS/EAX (Numba JIT работает на одном ядре). Оптимизация
  листьев параллелизуема, но полировка --- нет.

- **Аномалия данных att532.** Бенчмарк v6 выдал некорректные значения разрыва
  для att532, что указывает на проблему с функцией расстояния для
  псевдоевклидовых (ATT) экземпляров.

- **Отсутствие теоретических гарантий аппроксимации.** MASTm является эвристикой.
  В отличие от алгоритма Кристофидеса (3/2-аппроксимация), верхняя оценка
  худшего случая не установлена.

### Направления будущей работы

1. **EAX на Numba.** Устранение накладных расходов Python-множеств в
   EAX-кроссовере может снизить эффективный порог с N = 5000 до N = 1000.

2. **Block EAX.** Более сильный оператор возмущения для N > 10,000, где
   одиночные AB-цикловые кроссоверы имеют убывающую отдачу.

3. **Адаптивный размер листа.** Динамическая настройка размера листа иерархии
   на основе cv_nn_dist (гипотеза D' из заметок разработки).

4. **Многоядерная полировка.** Параллелизация перезапусков ILS по ядрам
   обеспечит близкое к линейному ускорение доминирующей фазы.

5. **Прямое сравнение с LKH-3.** Запуск LKH-3 на том же оборудовании с теми же
   временными бюджетами для установления справедливого сравнения.

6. **Асимметричная и ограниченная TSP.** Расширение MASTm на ATSP, CVRP и
   TSPTW варианты.

7. **Обученная маршрутизация.** Замена маршрутизатора на основе правил
   легковесной моделью, обученной на тройках (отпечаток, стратегия, разрыв).

---

## 11. Воспроизведение результатов

### Предварительные требования

```bash
pip install numpy scipy numba tsplib95 matplotlib
```

Экземпляры TSPLIB необходимо разместить в каталоге `data/tsplib/`. Оптимальные
значения встроены в скрипты бенчмарков.

### Запуск бенчмарков

Малые экземпляры (N <= 1000), бюджет 120 с, 3 запуска:

```bash
python3 scripts/benchmark.py --suite small --budget 120 --runs 3 \
    --output results/v6_benchmark_120s.json
```

Крупные экземпляры (N > 1000), бюджет 300 с, 5 запусков:

```bash
python3 scripts/benchmark.py --suite large --budget 300 --runs 5 \
    --output results/v6.6_large_300s.json
```

Ультрамасштаб (N > 10,000), расширенный бюджет:

```bash
python3 scripts/benchmark.py --suite ultra --budget 1800 --runs 1 \
    --output results/v5.0_ultra.json
```

### Файлы результатов

Все выходные данные бенчмарков хранятся в формате JSON в каталоге `results/`:

| Файл | Описание |
|------|----------|
| `v3.2_benchmark.json` | Начальная базовая линия, конвейер v3.2 |
| `v4.0_benchmark.json` | v4.0 с роем + MCTS |
| `v5.0_ultra.json` | Ультрамасштаб (N до 100K) |
| `v5.1_quick_bench.json` | Внедрение LK-DLB |
| `v6_benchmark_120s.json` | Полный набор v6, 120 с |
| `v6.6_large_300s.json` | Крупные экземпляры v6.6, 300 с |
| `v6.6_adaptive_spectral.json` | Адаптивная декомпозиция v6.6 |

---

*Последнее обновление: 2026-02-03*
